---
title: "Accessing data from the Internet"
subtitle: '<br/>ðŸ—º<br/>Transport Data Science'
author: "Robin Lovelace"
date: 'University of Leeds'
format: revealjs
bibliography: ../tds.bib
---

## Objectives

-   

    ## <font color="red">Learn where to find large transport datasets and assess data quality</font>

```{r}
# Understand the structure of transport datasets: spatial, temporal and demographic
# Understand how to obtain, clean and store transport related data
# Gain proficiency in command-line tools for handling large transport datasets
# Learn machine learning and data modelling techniques
# Produce data visualizations, static and interactive
# Learn where to find large transport datasets and assess data quality
# Learn how to join together the components of transport data science into a cohesive project portfolio 
```

## Learning outcomes

-   

    ## <font color="red">Identify available datasets and access and clean them</font>

```{r}
# Identify available datasets and access and clean them
# Combine datasets from multiple sources
# Understand what machine learning is, which problems it is appropriate for compared with traditional statistical approaches, and how to implement machine learning techniques
# Visualise and communicate the results of transport data science, and know about setting-up interactive web applications
# Deciding when to use local computing power vs cloud services
```

## This lecture will...

::: incremental
-   Be primarily practical
-   Provide an overview of data access options
-   Show how R packages and web services provide access to some datasets
:::

## Data access in context

::: incremental
-   Data cleaning (or 'tidying' or 'wrangling') is part of a wider process [@wickham_data_2023]

```{r, echo=FALSE}
knitr::include_graphics("https://d33wubrfki0l68.cloudfront.net/795c039ba2520455d833b4034befc8cf360a70ba/558a5/diagrams/data-science-explore.png")
```

-   It's important to have an idea where you're heading with the analysis

-   Often best to start with pen and paper
:::

## Data access/cleaning vs modelling time

<blockquote class="twitter-tweet" data-lang="en">

<p lang="en" dir="ltr">

Tapson's Rules of Machine Learning:<br>4.
Time spent on data cleaning is an order of magnitude more productive than time spent on hyperparameter tuning.<br><br>(Extreme example: achieved a Top 10 result in Kaggle using linear regression, as the only team that cleaned 50/60Hz noise first.)

</p>

â€” Jonathan Tapson (@jontapson) <a href="https://twitter.com/jontapson/status/1103024752019402753?ref_src=twsrc%5Etfw">March 5, 2019</a>

</blockquote>

```{=html}
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
```

Source: https://twitter.com/jontapson/status/1103024752019402753

background-image: url() background-size: cover class: center, middle

# A typology of data sources

## Information and data pyramids

Data science is climbing the DIKW pyramid

```{r, echo=FALSE}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/thumb/0/06/DIKW_Pyramid.svg/220px-DIKW_Pyramid.svg.png")
```

## A geographic availability pyramid

-   Recommendations

-   Build this here!

-   City-specific datasets

    -   Bristol cycle count data

-   Hard-to-access national data

-   Open international/national datasets

    -   Open origin-destination data from UK Census

-   Globally available, low-grade data (bottom)

    -   OpenStreetMap, Elevation data

## An ease-of access pyramid

-   Data provision packages
    -   Use the pct package
    -   stats19 package
-   Pre-processed data
    -   E.g. downloading data from website www.pct.bike
-   Messy official data
    -   Raw STATS19 data

## A geographic level of detail pyramid

-   Agents
-   Route networks
-   Nodes
-   Routes
-   Desire lines
-   Transport zones

## Observations

-   Official sources are often smaller in sizes but higher in Quality

-   Unofficial sources provide higher volumes but tend to be noisy

-   Another way to classify data is by quality: signal/noise ratios

-   Globally available datasets would be at the bottom of this pyramid; local surveys at the top.

-   Which would be best to inform policy?

## Portals

-   [UK geoportal](https://geoportal.statistics.gov.uk), providing geographic data at many levels
-   [Other national geoportals](http://www.geoportal.org/) exist
-   A good source of cleaned origin destination data is the Region downloads tab in the Propensity to Cycle Tool - see the [Region data tab for West Yorkshire here](http://www.pct.bike/m/?r=west-yorkshire), for example
-   [OpenStreetMap](https://www.openstreetmap.org/) is an excellent source of geographic data with global coverage. You can download data on specific queries (e.g. highway=cycleway) from the [overpass-turbo service](https://overpass-turbo.eu/) or with the **osmdata** or **osmextract** packages

## Online lists

For other datasets, search online!
Good starting points in your research may be:

-   The open data section in [Geocomputation with R (r.geocompx.org/read-write)](https://r.geocompx.org/read-write)
<!-- https://data.world/datasets/transportation -->
-   Transport datasets mentioned in [data.world](https://data.world/datasets/transportation)
<!-- https://www.gov.uk/government/organisations/department-for-transport/about/statistics -->
-   UK government transport data: [Department for Transport](https://www.gov.uk/government/organisations/department-for-transport/about/statistics)

## Data packages

-   The **openrouteservice** github package provides routing data
-   The stats19 package can get road crash data for anywhere in Great Britain [@lovelace_stats19_2019] see [docs.ropensci.org/stats19](https://docs.ropensci.org/stats19)
<!-- https://github.com/ITSLeeds/pct -->
-   The pct package provides access to data in the PCT project, including origin-destination data for the UK [@lovelace_propensity_2017] see [github.com/ITSLeeds/pct](https://github.com/ITSLeeds/pct)
<!-- https://github.com/ropenspain/spanishoddata -->
-   There are many other R packages to help access data, including the [spanishoddata](https://github.com/ropenspain/spanishoddata) package for Spanish origin-destination data

## Practical demo

See practical session at [itsleeds.github.io/tds/s2/](https://itsleeds.github.io/tds/s2/)

-   That involves:

-   Getting data from OSM: overpass turbo

-   Data from stats19

-   Data from the Census

-   Bonus: getting data from Cadence platform

## References