---
title: "Session 2: Getting transport datasets with R"
toc: true
execute: 
  cache: true
  #eval: true
  warning: false
  message: false
bibliography: ../tds.bib
#jupyter: python3
engine: knitr
---

# Introduction

In this session, we will learn how to get transport datasets using R.
The contents of the session are as follows:

- We'll start with a short lecture on data sources and ways of classifying transport datasets (see the [slides](https://itsleeds.github.io/tds/s2/slides.html))
- Reviewing the homework from the previous session
- Session activities: importing and exploring a range of transport datasets in your own time
- Bonus: exploring the Cadence platform
- Homework for the next session

## Review Homework

You should now be familiar with the basics of R, Quarto and the structure of transport datasets, having completed the [homework](https://itsleeds.github.io/tds/p1/#homework) from the previous session.

We will do a demo of trying to reproduce the demo from last week and discuss any issues you had running the code in Chapter 13 of [Geocomputation with R](https://r.geocompx.org).

## Prerequisites

Note: you may need to install the `pct` package as follows:

```
remotes::install_github("ITSLeeds/pct")
```

We will also load the following packages:

```{r}
#| results: hide
library(tidyverse)
library(sf)
library(tmap)
```

Note that this session uses imports and uses geographic data with the `sf` package.
Read more about the package in chapters 2 onwards in [Geocomputation with R](https://r.geocompx.org) and in the [sf package documentation](https://r-spatial.github.io/sf/).

# Getting OpenStreetMap data

Work through the reproducible code in the "Introducing osmextract" vignette hosted at [https://docs.ropensci.org/osmextract/articles/osmextract.html](https://docs.ropensci.org/osmextract/articles/osmextract.html).

## Bonus exercises

- Reproduce the examples
- Get all supermarkets in OSM for West Yorkshire
- Identify all cycleways in West Yorkshire and, using the stats19 data you have already downloaded, identify all crashes that happened near them.

```{r}
#| eval: false
#| echo: false
library(tidyverse)
library(osmextract)
region_name = "west yorkshire"
supermarket_points = oe_get(
  place = region_name,
  extra_tags = "shop",
  query = "SELECT * FROM points WHERE shop='supermarket'"
)
supermarket_polygons = oe_get(
  place = region_name,
  extra_tags = "shop",
  query = "SELECT * FROM multipolygons WHERE shop='supermarket'"
)
nrow(supermarket_points) # 81
nrow(supermarket_polygons) # 261
# Deduplicate points
supermarket_points_in_polygons = supermarket_points |>
  sf::st_filter(supermarket_polygons)
nrow(supermarket_points_in_polygons)  # none
supermarket_polygon_centroids = supermarket_polygons |>
  sf::st_centroid()
waldo::compare(names(supermarket_points), names(supermarket_polygons))
supermarket_points_combined = rbind(
  supermarket_points |>
    select(osm_id, name),
  supermarket_polygon_centroids |>
    select(osm_id, name)  
)
supermarket_frequency = supermarket_points_combined |>
  count(name, sort = TRUE)
length(supermarket_frequency$name) # 77
supermarket_frequency$name[1:20]
supermarket_points_cleaned = supermarket_points_combined |>
  mutate(
    name = case_when(
      name == "" ~ "Unnamed",
      str_detect(name, "Tesco") ~ "Tesco",
      str_detect(name, "Sainsbury") ~ "Sainsbury's",
      str_detect(name, "Asda") ~ "Asda",
      str_detect(name, "Morrisons") ~ "Morrisons",
      str_detect(name, "Aldi|ALDI") ~ "ALDI",
      str_detect(name, "Lidl") ~ "Lidl",
      str_detect(name, "Co-op|Coop") ~ "Co-op",
      str_detect(name, "M&S|Marks & Spencer") ~ "M&S",
      TRUE ~ name
    )
  )
supermarket_frequency_cleaned = supermarket_points_cleaned |>
  count(name, sort = TRUE)
length(supermarket_frequency_cleaned$name) # 66
supermarket_top_6 = supermarket_frequency_cleaned |>
  slice_max(n, n = 6)
supermarket_points_cleaned = supermarket_points_cleaned |>
  mutate(name_simplified = case_when(
    name %in% supermarket_top_6$name ~ name,
    TRUE ~ "Other"
  )) 
# Save the result:
sf::st_write(supermarket_points_cleaned, "supermarkets_points_cleaned.geojson", delete_dsn = TRUE)
system("gh release upload 2025 supermarkets_points_cleaned.geojson --clobber")
```

Import and visualise a dataset with supermarket names and locations with the following code (see the [source code of the session](https://github.com/itsleeds/tds/discussions/166) to see how the supermarket data was obtained with `osmextract`):

```{r}
supermarkets = sf::read_sf("https://github.com/ITSLeeds/tds/releases/download/2025/supermarkets_points_cleaned.geojson")
library(tmap)
tmap_mode("view")
tm_shape(supermarkets) +
  tm_dots("name_simplified")
```

# Getting road traffic casualty data

Work through the reproducible code in the ["Getting started with stats19" vignette hosted at docs.ropensci.org/stats19](https://docs.ropensci.org/stats19/articles/stats19.html).

# Boundary datasets

Boundary datasets are useful for mapping and spatial analysis, providing the geographical context for other datasets.
You can download geographic datasets directly from the [ONS Geoportal](https://geoportal.statistics.gov.uk/).

You can also search for boundary datasets using the `esri2sf` package, which provides a function `esrisearch` to search for datasets on the ESRI ArcGIS platform.
To illustrate this programatic way of getting boundary data, we will search for the "Local Authority Districts December 2024 Boundaries UK" dataset and download it using the `arcgis` package.

```{r}
#| eval: false
pak::pkg_install("elipousson/esri2sf")
remotes::install_github("r-arcgis/arcgis", dependencies = TRUE)
res = esri2sf::esrisearch("Local Authority Districts (May 2023) Boundaries UK")
res = res |>
  dplyr::filter(type == "Feature Service") |>
  # # 2023 versions:
  # dplyr::filter(str_detect(title, "2023")) |>
  # BUC: 
  dplyr::filter(str_detect(title, "BUC")) 
res$title
u_from_res = paste0(res$url[1], "/0")
library(arcgis)
res_sf = arc_read(u_from_res)
plot(res_sf$geometry)
```

# Census data

## The ONS "create a custom dataset" tool

The Office for National Statistics (ONS) provides a tool to create custom datasets. The tool is flexible and provides datasets in a variety of formats, including CSV. Give the tool a try at [www.ons.gov.uk/datasets/create](https://www.ons.gov.uk/datasets/create).
To test the tool, try to get data on travel to work patterns for all usual residents in England and Wales at the local authority level (note: you may need to change the file name to match the one you downloaded).

```{r}
#| eval: false
#| echo: false
# Upload result to GitHub release
system("gh release list")
system("gh release upload 2025 custom-filtered-2025-02-04T00_06_30Z.csv")

# And res_sf:
sf::write_sf(res_sf, "lad_boundaries_2023.geojson")
system("gh release upload 2025 lad_boundaries_2023.geojson")
```

```{r}
#| echo: false
# Download the datasets:
base_url = "https://github.com/ITSLeeds/tds/releases/download/2025/"
if (!file.exists("custom-filtered-2025-02-04T00_06_30Z.csv")) {
  download.file(paste0(base_url, "custom-filtered-2025-02-04T00_06_30Z.csv"), "custom-filtered-2025-02-04T00_06_30Z.csv")
}
if (!file.exists("lad_boundaries_2023.geojson")) {
  download.file(paste0(base_url, "lad_boundaries_2023.geojson"), "lad_boundaries_2023.geojson")
}
```

```{r}
res_sf = sf::st_read("lad_boundaries_2023.geojson")
travel_to_work_lad = readr::read_csv("custom-filtered-2025-02-04T00_06_30Z.csv")
# names(travel_to_work_lad)
# [1] "Lower tier local authorities Code"                      
# [2] "Lower tier local authorities"                           
# [3] "Distance travelled to work (8 categories) Code"         
# [4] "Distance travelled to work (8 categories)"              
# [5] "Method used to travel to workplace (12 categories) Code"
# [6] "Method used to travel to workplace (12 categories)"     
# [7] "Observation" 
travel_to_work_updated = travel_to_work_lad |>
  select(
    LAD23CD = `2023 Lower tier local authorities Code`,
    Mode = `Method used to travel to workplace (12 categories)`,
    Distance = `Distance travelled to work (8 categories)`,
    Observation = Observation
  )
# Pivot wider:
ttw_wide = travel_to_work_updated |>
  pivot_wider(names_from = c(Distance, Mode), values_from = Observation)
summary(res_sf[["LAD23CD"]] %in% travel_to_work_lad[[1]]) 
# Other way around:
summary(travel_to_work_lad[[1]] %in% res_sf[["LAD23CD"]])
# names(ttw_wide)
```

# The cadence platform

Sign up to Cadence website at [cadence360.cityscience.com/](https://cadence360.cityscience.com/) by clicking 'Sign In' in the top right. New users can then either create an account or sign in to an existing account.

# Joining datasets

Two key ways to join datasets are by spatial location and by a common key. We will demonstrate the latter using the `dplyr` package.

```{r}
lad_joined = left_join(
  res_sf,
  ttw_wide
)
```

Let's visualise the results with a choropleth map made using `ggplot2`.

```{r}
ggplot(lad_joined) +
  geom_sf(aes(fill = `Less than 5km_Driving a car or van`), colour = NA) +
  scale_fill_viridis_c() +
  theme_minimal()
```

See [r.geocompx.org/spatial-operations](https://r.geocompx.org/spatial-operations#spatial-joining) for spatial joins.

# Homework

1. In preparation for the next session, take a read of and try to reproduce the code in the [vignette "An introduction to origin-destination data"](https://cran.r-project.org/web/packages/od/vignettes/od.html) for the `od` package.
<!-- https://itsleeds.github.io/pct/articles/pct.html -->
    - Import some OD data using the `pct` package, as documented at [itsleeds.github.io/pct](https://itsleeds.github.io/pct/articles/pct.html).

2. Download and visualise 3 transport-related datasets of your choice and save the results in a reproducible .qmd file.
    - Bonus: generate a .pdf document showing the results.

3. Take a quick read of, and try to reproduce some of the code in, at least three of the chapters in R4DS:
    - [Chapter 1: Data visualisation](https://r4ds.hadley.nz/data-visualize)
    - [Chapter 3: Data transformation](https://r4ds.hadley.nz/data-transform.html)
    - [Chapter 28: Quarto](https://r4ds.hadley.nz/quarto.html)
    - One of you choice, e.g. 
        - [Chapter 5: Data tidying](https://r4ds.hadley.nz/data-tidy.html)
        - [Chapter 19: Joins](https://r4ds.hadley.nz/joins.html)

4. Try to reproduce and modify the code I wrote during the live demo to get OSM data for a city of your choice.
    - See the [source code here: https://github.com/itsleeds/tds/blob/main/p2/demo.qmd](https://github.com/itsleeds/tds/blob/main/p2/demo.qmd)
    - See the results here: [https://itsleeds.github.io/tds/p2/demo.html](https://itsleeds.github.io/tds/p2/demo.html)

5. Check-out the code I used to generate the interactive map of source code in this Discussion on GitHub: https://github.com/itsleeds/tds/discussions/166
    - Bonus: comment on the discussion with your thoughts on the code and how it could be improved.
    - Bonus 2: try opening a new Discussion comment in the tds repo at [github.com/itsleeds/tds/discussions](https://github.com/itsleeds/tds/discussions) and share your thoughts on the session.
